{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mistral AI search engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<details>\n",
       "<summary>Click to view session information</summary>\n",
       "<pre>\n",
       "-----\n",
       "aiohttp             3.9.5\n",
       "bs4                 4.12.3\n",
       "dotenv              NA\n",
       "faiss               1.8.0\n",
       "lxml                5.2.2\n",
       "mistralai           NA\n",
       "nest_asyncio        NA\n",
       "numpy               1.26.4\n",
       "pandas              2.2.2\n",
       "requests            2.32.3\n",
       "session_info        1.0.0\n",
       "-----\n",
       "</pre>\n",
       "<details>\n",
       "<summary>Click to view modules imported as dependencies</summary>\n",
       "<pre>\n",
       "aiosignal           1.3.1\n",
       "annotated_types     0.7.0\n",
       "anyio               NA\n",
       "appnope             0.1.4\n",
       "asttokens           NA\n",
       "async_timeout       4.0.3\n",
       "attr                23.2.0\n",
       "certifi             2024.06.02\n",
       "charset_normalizer  3.3.2\n",
       "comm                0.2.2\n",
       "cython_runtime      NA\n",
       "dateutil            2.9.0\n",
       "debugpy             1.6.7\n",
       "decorator           5.1.1\n",
       "exceptiongroup      1.2.0\n",
       "executing           2.0.1\n",
       "frozenlist          1.4.1\n",
       "h11                 0.14.0\n",
       "httpcore            1.0.5\n",
       "httpx               0.25.2\n",
       "idna                3.7\n",
       "ipykernel           6.29.4\n",
       "jedi                0.19.1\n",
       "multidict           6.0.5\n",
       "orjson              3.10.4\n",
       "packaging           24.0\n",
       "parso               0.8.4\n",
       "pickleshare         0.7.5\n",
       "pkg_resources       NA\n",
       "platformdirs        4.2.2\n",
       "prompt_toolkit      3.0.47\n",
       "psutil              5.9.0\n",
       "pure_eval           0.2.2\n",
       "pydantic            2.7.3\n",
       "pydantic_core       2.18.4\n",
       "pydev_ipython       NA\n",
       "pydevconsole        NA\n",
       "pydevd              2.9.5\n",
       "pydevd_file_utils   NA\n",
       "pydevd_plugins      NA\n",
       "pydevd_tracing      NA\n",
       "pygments            2.18.0\n",
       "pytz                2024.1\n",
       "six                 1.16.0\n",
       "sniffio             1.3.1\n",
       "soupsieve           2.5\n",
       "stack_data          0.6.2\n",
       "swig_runtime_data4  NA\n",
       "tornado             6.3.3\n",
       "traitlets           5.14.3\n",
       "typing_extensions   NA\n",
       "urllib3             2.2.1\n",
       "vscode              NA\n",
       "wcwidth             0.2.13\n",
       "yarl                1.9.4\n",
       "zmq                 25.1.2\n",
       "zoneinfo            NA\n",
       "</pre>\n",
       "</details> <!-- seems like this ends pre, so might as well be explicit -->\n",
       "<pre>\n",
       "-----\n",
       "IPython             8.25.0\n",
       "jupyter_client      8.6.2\n",
       "jupyter_core        5.5.0\n",
       "-----\n",
       "Python 3.10.14 (main, May  6 2024, 14:42:37) [Clang 14.0.6 ]\n",
       "macOS-14.4-arm64-arm-64bit\n",
       "-----\n",
       "Session information updated at 2024-06-11 03:48\n",
       "</pre>\n",
       "</details>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import session_info\n",
    "session_info.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install aiohttp bs4 faiss-cpu lxml mistralai nest_asyncio nest_asyncio pandas requests python-dotenv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![image info](./images/mistral-search-graph.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv()  # load environment variables from .env file\n",
    "MISTRAL_API_KEY = os.getenv(\"MISTRAL_API_KEY\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scraper Definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching page: 1\n",
      "Fetching page: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <function MistralClient.__del__ at 0x11efd1ab0>\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/hugolebelzic/miniconda3/envs/mistral-cookbook-contrib/lib/python3.10/site-packages/mistralai/client.py\", line 49, in __del__\n",
      "    self._client.close()\n",
      "AttributeError: 'MistralClient' object has no attribute '_client'\n"
     ]
    }
   ],
   "source": [
    "import aiohttp\n",
    "import asyncio\n",
    "import nest_asyncio\n",
    "from bs4 import BeautifulSoup\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "import requests\n",
    "import re\n",
    "import pandas as pd\n",
    "import faiss\n",
    "import numpy as np\n",
    "from mistralai.client import MistralClient\n",
    "from mistralai.models.chat_completion import ChatMessage\n",
    "\n",
    "# Apply the nest_asyncio patch\n",
    "nest_asyncio.apply()\n",
    "\n",
    "headers = {\n",
    "    \"User-Agent\": \"Mozilla/5.0 (Windows NT 6.1; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/108.0.0.0 Safari/537.36\"\n",
    "}\n",
    "\n",
    "total_results_to_fetch = 10  # total number of results to fetch\n",
    "chunk_size = 1000  # size of each text chunk\n",
    "\n",
    "dataframe_out_path = 'temp.csv'\n",
    "faiss_index_path = 'faiss_index.index'\n",
    "\n",
    "mistral_api_key = MISTRAL_API_KEY  # replace with your actual API key\n",
    "\n",
    "async def fetch(session, url, params=None):\n",
    "    async with session.get(url, params=params, headers=headers, timeout=30) as response:\n",
    "        return await response.text()\n",
    "\n",
    "async def fetch_page(session, params, page_num, results):\n",
    "    print(f\"Fetching page: {page_num}\")\n",
    "    params[\"start\"] = (page_num - 1) * params[\"num\"]\n",
    "    html = await fetch(session, \"https://www.google.com/search\", params)\n",
    "    soup = BeautifulSoup(html, 'html.parser')\n",
    "\n",
    "    for result in soup.select(\".tF2Cxc\"):\n",
    "        if len(results) >= total_results_to_fetch:\n",
    "            break\n",
    "        title = result.select_one(\".DKV0Md\").text\n",
    "        links = result.select_one(\".yuRUbf a\")[\"href\"]\n",
    "\n",
    "        results.append({\n",
    "            \"title\": title,\n",
    "            \"links\": links\n",
    "        })\n",
    "\n",
    "async def fetch_content(session, url):\n",
    "    async with session.get(url, headers=headers, timeout=30) as response:\n",
    "        return await response.text()\n",
    "\n",
    "async def fetch_all_content(urls):\n",
    "    async with aiohttp.ClientSession() as session:\n",
    "        tasks = [fetch_content(session, url) for url in urls]\n",
    "        return await asyncio.gather(*tasks)\n",
    "\n",
    "def get_all_text_from_url(url):\n",
    "    response = requests.get(url, headers=headers, timeout=30)\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "    for script in soup([\"script\", \"style\"]):\n",
    "        script.extract()\n",
    "    text = soup.get_text()\n",
    "    lines = (line.strip() for line in text.splitlines())\n",
    "    chunks = (phrase.strip() for line in lines for phrase in line.split(\"  \"))\n",
    "    text = '\\n'.join(chunk for chunk in chunks if chunk)\n",
    "    return text\n",
    "\n",
    "def split_text_into_chunks(text, chunk_size):\n",
    "    sentences = re.split(r'(?<=[.!?]) +', text)\n",
    "    chunks = []\n",
    "    current_chunk = []\n",
    "\n",
    "    for sentence in sentences:\n",
    "        if sum(len(s) for s in current_chunk) + len(sentence) + 1 > chunk_size:\n",
    "            chunks.append(' '.join(current_chunk))\n",
    "            current_chunk = [sentence]\n",
    "        else:\n",
    "            current_chunk.append(sentence)\n",
    "\n",
    "    if current_chunk:\n",
    "        chunks.append(' '.join(current_chunk))\n",
    "\n",
    "    return chunks\n",
    "\n",
    "async def process_text_content(texts, chunk_size):\n",
    "    loop = asyncio.get_event_loop()\n",
    "    tasks = [loop.run_in_executor(None, split_text_into_chunks, text, chunk_size) for text in texts]\n",
    "    return await asyncio.gather(*tasks)\n",
    "\n",
    "async def get_embeddings_from_mistral(client, text_chunks):\n",
    "    response = client.embeddings(model=\"mistral-embed\", input=text_chunks)\n",
    "    return [embedding.embedding for embedding in response.data]\n",
    "\n",
    "async def fetch_and_process_data(search_query):\n",
    "    client = MistralClient(api_key=mistral_api_key)\n",
    "\n",
    "    params = {\n",
    "        \"q\": search_query,  # query example\n",
    "        \"hl\": \"en\",         # language\n",
    "        \"gl\": \"uk\",         # country of the search, UK -> United Kingdom\n",
    "        \"start\": 0,         # number page by default up to 0\n",
    "        \"num\": 10           # parameter defines the maximum number of results to return per page.\n",
    "    }\n",
    "    \n",
    "    async with aiohttp.ClientSession() as session:\n",
    "        page_num = 0\n",
    "        results = []\n",
    "        while len(results) < total_results_to_fetch:\n",
    "            page_num += 1\n",
    "            await fetch_page(session, params, page_num, results)\n",
    "\n",
    "        urls = [result['links'] for result in results]\n",
    "\n",
    "        with ThreadPoolExecutor(max_workers=10) as executor:\n",
    "            loop = asyncio.get_event_loop()\n",
    "            texts = await asyncio.gather(\n",
    "                *[loop.run_in_executor(executor, get_all_text_from_url, url) for url in urls]\n",
    "            )\n",
    "\n",
    "        chunks_list = await process_text_content(texts, chunk_size)\n",
    "\n",
    "        embeddings_list = []\n",
    "        for chunks in chunks_list:\n",
    "            embeddings = await get_embeddings_from_mistral(client, chunks)\n",
    "            embeddings_list.append(embeddings)\n",
    "\n",
    "        data = []\n",
    "        for i, result in enumerate(results):\n",
    "            if i >= len(embeddings_list):\n",
    "                print(f\"Error: No embeddings returned for result {i}\")\n",
    "                continue\n",
    "            for j, chunk in enumerate(chunks_list[i]):\n",
    "                if j >= len(embeddings_list[i]):\n",
    "                    print(f\"Error: No embedding returned for chunk {j} of result {i}\")\n",
    "                    continue\n",
    "                data.append({\n",
    "                    'title': result['title'],\n",
    "                    'url': result['links'],\n",
    "                    'chunk': chunk,\n",
    "                    'embedding': embeddings_list[i][j]\n",
    "                })\n",
    "\n",
    "        df = pd.DataFrame(data)\n",
    "        df.to_csv(dataframe_out_path, index=False)\n",
    "\n",
    "        # FAISS indexing\n",
    "        dimension = len(embeddings_list[0][0])  # assuming all embeddings have the same dimension\n",
    "        index = faiss.IndexFlatL2(dimension)\n",
    "\n",
    "        embeddings = np.array([entry['embedding'] for entry in data], dtype=np.float32)\n",
    "        index.add(embeddings)\n",
    "\n",
    "        faiss.write_index(index, faiss_index_path)\n",
    "\n",
    "await fetch_and_process_data(\"What is the latest news about apple and openai?\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## little embeddings and vector store creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'title': 'Apple announces deal with OpenAI. Will it be a game- ...',\n",
       "  'url': 'https://www.latimes.com/entertainment-arts/business/story/2024-06-10/apple-announces-leap-into-ai-will-it-be-a-game-changer',\n",
       "  'chunk': '“This is a method to allow Apple to make up for the fact that they haven’t been focused on AI like they should have done over the last decade or so.” Apple Intelligence was one of many announcements and updates from Apple\\non Monday, including a feature that lets AirPods Pro users nod yes or shake their heads no to Siri’s questions when they are in crowded spaces. Additionally, the company announced that the\\nVision Pro headset will also be available in additional countries starting later this month, including mainland China, Hong Kong, Japan and Singapore.The company also unveiled a new feature called InSight for its tvOS18 that is similar to Amazon’s X-Ray and shows the names of actors or a song playing on an Apple TV+ program.\\nCompany Town\\nScarlett Johansson also thinks OpenAI’s new voice sounds like her. She’s not happy about it\\nJohansson, who portrayed the voice of a computer program in ‘Her,’ was not behind OpenAI’s ‘Sky’ voice assistant.'},\n",
       " {'title': 'Apple doubles down on artificial intelligence, announcing ...',\n",
       "  'url': 'https://www.npr.org/2024/06/10/nx-s1-4999051/apple-artificial-intelligence-partnership-openai-chatgpt-siri-iphone',\n",
       "  'chunk': \"OpenAI itself has been embroiled in allegations of copying actor Scartlett Johansson’s voice without her permission. Apple is also at the center of an antitrust lawsuit filed by the Justice Department and 15 states. The government accuses Apple of abusing its power as a monopoly to push out rivals and keep customers using its products. It’s unclear how Apple’s new partnership with OpenAI could play into this case. Shortly after Apple’s announcement, OpenAI CEO Sam Altman posted on X, formerly known as Twitter, “very happy to be partnering with apple to integrate chatgpt into their devices later this year! think you will really like it.”\\nApple is also rolling out what it calls Apple Intelligence, its term for Apple's own new generative AI software. Apple Intelligence will enable transcription for phone calls, AI photo retouching and improvements in the natural conversation flow with Siri, the company said.\"},\n",
       " {'title': 'Apple announces deal with OpenAI. Will it be a game- ...',\n",
       "  'url': 'https://www.latimes.com/entertainment-arts/business/story/2024-06-10/apple-announces-leap-into-ai-will-it-be-a-game-changer',\n",
       "  'chunk': 'Tools made by San Francisco-based OpenAI have been used to create\\nmusic videos, read bedtime stories to children and help brainstorm ideas for writers. Companies including Microsoft and Google have aggressively incorporated AI into their products and services. Apple has often not been the first to market with new technological advances, choosing instead to enter new product categories — including smartphones and tablets — once they’ve been established, leading to broader consumer adoption. For example, Apple only began selling its own virtual and augmented reality headset (known as Vision Pro) early this year.\\nApple said its AI capabilities were created with privacy protections in mind.'},\n",
       " {'title': 'Apple announces deal with OpenAI. Will it be a game- ...',\n",
       "  'url': 'https://www.latimes.com/entertainment-arts/business/story/2024-06-10/apple-announces-leap-into-ai-will-it-be-a-game-changer',\n",
       "  'chunk': 'Apple announces deal with OpenAI. Will it be a game-changer? - Los Angeles Times\\nNews\\nHome Page\\nCalifornia\\nElection 2024\\nHousing & Homelessness\\nPolitics\\nScience & Medicine\\nWorld & Nation\\nBusiness\\nArtificial Intelligence\\nAutos\\nJobs, Labor & Workplace\\nReal Estate\\nTechnology and the Internet\\nCalifornia\\nCalifornia Politics\\nEarthquakes\\nEducation\\nHousing & Homelessness\\nL.A. Influential\\nL.A. Politics\\nMental Health\\nClimate & Environment\\nGlobal Warming\\nWater & Drought\\nEntertainment & Arts\\nArts\\nBooks\\nStand-Up Comedy\\nCompany Town\\nThe Envelope (Awards)\\nMovies\\nMusic\\nTelevision\\nThings to Do\\nDe Los\\nEn Español\\nFood\\n101 best restaurants in L.A.\\nRecipes\\nImage\\nLifestyle\\nHealth & Wellness\\nHome Design\\nL.A.'},\n",
       " {'title': 'OpenAI and Apple announce partnership',\n",
       "  'url': 'https://openai.com/index/openai-and-apple-announce-partnership/',\n",
       "  'chunk': \"Together with Apple, we're making it easier for people to benefit from what AI can offer.Sam Altman, CEO of OpenAIAnnouncementsCompanyAuthorOpenAI Our researchOverviewIndexLatest advancementsGPT-4DALL·E 3SoraChatGPTFor EveryoneFor TeamsFor EnterprisesChatGPT login(opens in a new window)APIPlatform overviewPricingDocumentation(opens in a new window)API login(opens in a new window)Explore moreOpenAI for businessStoriesSafety overviewSafety overviewSafety standardsTeamsSafety SystemsPreparednessSuperalignmentCompanyAbout usNewsOur CharterSecurityResidencyCareersTerms & policiesTerms of usePrivacy policyBrand guidelinesOther policies OpenAI © 2015–2024(opens in a new window)(opens in a new window)(opens in a new window)(opens in a new window)(opens in a new window)(opens in a new window)(opens in a new window)\"}]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def query_vector_store(query_embedding, k=5):\n",
    "    \"\"\"\n",
    "    Query the FAISS vector store and return the text results along with metadata.\n",
    "\n",
    "    :param query_embedding: The embedding to query with.\n",
    "    :param k: Number of nearest neighbors to retrieve.\n",
    "    :return: List of dictionaries containing text results and metadata of the k nearest neighbors.\n",
    "    \"\"\"\n",
    "    # Load the index\n",
    "\n",
    "    index = faiss.read_index(faiss_index_path)\n",
    "\n",
    "    # Ensure the query embedding is a numpy array with the correct shape\n",
    "    if not isinstance(query_embedding, np.ndarray):\n",
    "        query_embedding = np.array(query_embedding, dtype=np.float32)\n",
    "    if query_embedding.ndim == 1:\n",
    "        query_embedding = np.expand_dims(query_embedding, axis=0)\n",
    "\n",
    "    # Query the index\n",
    "    distances, indices = index.search(query_embedding, k)\n",
    "    \n",
    "    # Load the dataframe\n",
    "    df = pd.read_csv(dataframe_out_path)\n",
    "    \n",
    "    # Retrieve the text results and metadata\n",
    "    results = []\n",
    "    for idx in indices[0]:\n",
    "        result = {\n",
    "            'title': df.iloc[idx]['title'],\n",
    "            'url': df.iloc[idx]['url'],\n",
    "            'chunk': df.iloc[idx]['chunk']\n",
    "        }\n",
    "        results.append(result)\n",
    "    \n",
    "    return results\n",
    "\n",
    "def query_embeddings(texts):\n",
    "    \"\"\"\n",
    "    Convert text to embeddings using Mistral AI API.\n",
    "\n",
    "    :param api_key: Your Mistral API key.\n",
    "    :param texts: List of texts to convert to embeddings.\n",
    "    :return: List of embeddings.\n",
    "    \"\"\"\n",
    "    client = MistralClient(api_key=MISTRAL_API_KEY)\n",
    "    response = client.embeddings(model=\"mistral-embed\", input=[texts])\n",
    "    return [embedding.embedding for embedding in response.data]\n",
    "\n",
    "\n",
    "embeddings = query_embeddings(\"AGI\")\n",
    "results = query_vector_store(embeddings[0], k=5)\n",
    "results\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## tools definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching page: 1\n",
      "Fetching page: 2\n",
      "[{'title': 'Microsoft partners with Mistral in second AI deal beyond ...', 'url': 'https://www.theverge.com/2024/2/26/24083510/microsoft-mistral-partnership-deal-azure-ai', 'chunk': '“Mistral Large achieves strong results on commonly used benchmarks, making it the world’s second-ranked model generally available through an API (next to GPT-4),” says the Mistral AI team.Mistral also has a new AI chatbotMistral Large is available on Mistral’s own infrastructure, hosted in Europe, or through Azure AI Studio and Azure Machine Learning. Mistral Small will also be available today, offering improved latency over Mistral’s 8x7B model. Mistral is also releasing a new conversational chatbot, Le Chat, that’s based on various models from Mistral AI.Mistral’s models have typically been open source, but the partnership with Microsoft means the French AI company can now explore more commercial opportunities. Neither Microsoft nor Mistral are disclosing details of the investment, though.Microsoft’s investment comes months after a rocky period for its main AI partner, OpenAI.'}, {'title': 'How Mistral AI, an OpenAI competitor, rocketed to $2Bn in ...', 'url': 'https://www.bensbites.com/case-study/how-mistral-ai-an-openai-competitor-rocketed-to-2bn-in-12-months', 'chunk': 'Something went wrong while submitting the form.PricingLog inSign upCase studies\\nHow Mistral AI, an OpenAI competitor, rocketed to $2Bn in <12 monthsHow Mistral AI, an OpenAI competitor, rocketed to $2Bn in <12 monthsSaveSavedToday Iâ\\x80\\x99m diving deep into Mistral AI, who are making headlines after recently closing their (huge) Series A round. Launched just 7 months ago, theyâ\\x80\\x99re disrupting the LLM market. I want to look at how theyâ\\x80\\x99re doing it - and how you can take advantage.This post covers:What is Mistral?Whoâ\\x80\\x99s behind it?The timeline: Whatâ\\x80\\x99s happened to dateFundraisingProduct OverviewA peek inside their seed deck ð\\x9f\\x91\\x80 Roadmap analysis. Are they achieving what they set out to do?5 big reasons Mistralâ\\x80\\x99s making waves ð\\x9f\\x8c\\x8aHow people actually use MistralOpportunities and how you can take advantageWhat developers think of MistralWhat is Mistral?A French startup that develops fast, open-source and secure language models.'}, {'title': 'How Mistral AI, an OpenAI competitor, rocketed to $2Bn in ...', 'url': 'https://www.bensbites.com/case-study/how-mistral-ai-an-openai-competitor-rocketed-to-2bn-in-12-months', 'chunk': 'As Mistral has been true to the promise of releasing open models, the community (and other companies) have taken Mistralâ\\x80\\x99s models and created better models on top of them. For example, OpenHermes 2.5 by Teknium and Neural Chat 7B by Intel.With AI models, open source takes many forms: from available to use locally but no details about the model (weights, architecture etc.) to models that are fully open source and allow users to train on the outputs.While Mistralâ\\x80\\x99s models were open-weights from the start, Mistralâ\\x80\\x99s latest announcement had a line in their Terms of Service Terms of Service which was spotted by Far El on Twitter, said:Basically, you canâ\\x80\\x99t use it to train or improve other models or compete against themâ\\x80¦It wasnâ\\x80\\x99t clear whether this was just for the API platform or the model itself. And unfortunately, open-source means you should be able to use this tech how you like, thatâ\\x80\\x99s kind of the point.'}, {'title': 'Microsoft partners with Mistral in second AI deal beyond ...', 'url': 'https://www.theverge.com/2024/2/26/24083510/microsoft-mistral-partnership-deal-azure-ai', 'chunk': 'The Financial Times reports that the partnership will include Microsoft taking a minor stake in the 10-month-old AI company, just a little over a year after Microsoft invested more than $10 billion into its OpenAI partnership.The deal will see Mistral’s open and commercial language models available on Microsoft’s Azure AI platform, the second company to offer a commercial language model on Azure after OpenAI. Much like the OpenAI partnership, Microsoft’s partnership with Mistral will also be focused on the development and deployment of next-generation large language models.Mistral is announcing a new AI model today, called Mistral Large. It’s designed to more closely compete with OpenAI’s GPT-4 model. Unlike some of Mistral’s previous models, it won’t be open source.'}, {'title': 'Microsoft partners with Mistral in second AI deal beyond ...', 'url': 'https://www.theverge.com/2024/2/26/24083510/microsoft-mistral-partnership-deal-azure-ai', 'chunk': 'Microsoft partners with Mistral in second AI deal beyond OpenAI - The VergeSkip to main contentThe VergeThe Verge logo.The Verge homepageThe Verge homepageThe VergeThe Verge logo./Tech/Reviews/Science/Entertainment/AI/MoreMenuExpandThe VergeThe Verge logo.MenuExpandMicrosoft/Tech/Artificial IntelligenceMicrosoft partners with Mistral in second AI deal beyond OpenAIMicrosoft partners with Mistral in second AI deal beyond OpenAI / Mistral has a Microsoft investment to help commercialize its new AI language models.By\\nTom Warren, a senior editor covering Microsoft, PC gaming, console, and tech. He founded WinRumors, a site dedicated to Microsoft news, before joining The Verge in 2012. Feb 26, 2024, 3:23 PM UTCShare this story Illustration: The VergeMicrosoft has announced a new multiyear partnership with Mistral, a French AI startup that’s valued at €2 billion (about $2.1 billion).'}]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "nest_asyncio.apply()\n",
    "\n",
    "tools = [\n",
    "    {\n",
    "        \"type\": \"function\",\n",
    "        \"function\": {\n",
    "            \"name\": \"mistral_web_search\",\n",
    "            \"description\": \"Fetch and process data from Google search based on a query, store results in FAISS vector store, and retrieve results.\",\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"search_query\": {\n",
    "                        \"type\": \"string\",\n",
    "                        \"description\": \"The search query to use for fetching data from Google search.\"\n",
    "                    }\n",
    "                },\n",
    "                \"required\": [\"search_query\"]\n",
    "            },\n",
    "        },\n",
    "    },\n",
    "]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def mistral_web_search(search_query: str):\n",
    "    async def run_search():\n",
    "        await fetch_and_process_data(search_query)\n",
    "        embeddings = query_embeddings(search_query)\n",
    "        results_ = query_vector_store(embeddings[0], k=5)\n",
    "        return results_\n",
    "\n",
    "    return asyncio.run(run_search())\n",
    "\n",
    "search_query = \"mistral and openai\"\n",
    "results = mistral_web_search(search_query)\n",
    "print(results)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching page: 1\n",
      "Fetching page: 2\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'“Mistral Large achieves strong results on commonly used benchmarks, making it the world’s second-ranked model generally available through an API (next to GPT-4),” says the Mistral AI team.Mistral also has a new AI chatbotMistral Large is available on Mistral’s own infrastructure, hosted in Europe, or through Azure AI Studio and Azure Machine Learning. Mistral Small will also be available today, offering improved latency over Mistral’s 8x7B model. Mistral is also releasing a new conversational chatbot, Le Chat, that’s based on various models from Mistral AI.Mistral’s models have typically been open source, but the partnership with Microsoft means the French AI company can now explore more commercial opportunities. Neither Microsoft nor Mistral are disclosing details of the investment, though.Microsoft’s investment comes months after a rocky period for its main AI partner, OpenAI.\\nSomething went wrong while submitting the form.PricingLog inSign upCase studies\\nHow Mistral AI, an OpenAI competitor, rocketed to $2Bn in <12 monthsHow Mistral AI, an OpenAI competitor, rocketed to $2Bn in <12 monthsSaveSavedToday Iâ\\x80\\x99m diving deep into Mistral AI, who are making headlines after recently closing their (huge) Series A round. Launched just 7 months ago, theyâ\\x80\\x99re disrupting the LLM market. I want to look at how theyâ\\x80\\x99re doing it - and how you can take advantage.This post covers:What is Mistral?Whoâ\\x80\\x99s behind it?The timeline: Whatâ\\x80\\x99s happened to dateFundraisingProduct OverviewA peek inside their seed deck ð\\x9f\\x91\\x80 Roadmap analysis. Are they achieving what they set out to do?5 big reasons Mistralâ\\x80\\x99s making waves ð\\x9f\\x8c\\x8aHow people actually use MistralOpportunities and how you can take advantageWhat developers think of MistralWhat is Mistral?A French startup that develops fast, open-source and secure language models.\\nAs Mistral has been true to the promise of releasing open models, the community (and other companies) have taken Mistralâ\\x80\\x99s models and created better models on top of them. For example, OpenHermes 2.5 by Teknium and Neural Chat 7B by Intel.With AI models, open source takes many forms: from available to use locally but no details about the model (weights, architecture etc.) to models that are fully open source and allow users to train on the outputs.While Mistralâ\\x80\\x99s models were open-weights from the start, Mistralâ\\x80\\x99s latest announcement had a line in their Terms of Service Terms of Service which was spotted by Far El on Twitter, said:Basically, you canâ\\x80\\x99t use it to train or improve other models or compete against themâ\\x80¦It wasnâ\\x80\\x99t clear whether this was just for the API platform or the model itself. And unfortunately, open-source means you should be able to use this tech how you like, thatâ\\x80\\x99s kind of the point.\\nThe Financial Times reports that the partnership will include Microsoft taking a minor stake in the 10-month-old AI company, just a little over a year after Microsoft invested more than $10 billion into its OpenAI partnership.The deal will see Mistral’s open and commercial language models available on Microsoft’s Azure AI platform, the second company to offer a commercial language model on Azure after OpenAI. Much like the OpenAI partnership, Microsoft’s partnership with Mistral will also be focused on the development and deployment of next-generation large language models.Mistral is announcing a new AI model today, called Mistral Large. It’s designed to more closely compete with OpenAI’s GPT-4 model. Unlike some of Mistral’s previous models, it won’t be open source.\\nMicrosoft partners with Mistral in second AI deal beyond OpenAI - The VergeSkip to main contentThe VergeThe Verge logo.The Verge homepageThe Verge homepageThe VergeThe Verge logo./Tech/Reviews/Science/Entertainment/AI/MoreMenuExpandThe VergeThe Verge logo.MenuExpandMicrosoft/Tech/Artificial IntelligenceMicrosoft partners with Mistral in second AI deal beyond OpenAIMicrosoft partners with Mistral in second AI deal beyond OpenAI / Mistral has a Microsoft investment to help commercialize its new AI language models.By\\nTom Warren, a senior editor covering Microsoft, PC gaming, console, and tech. He founded WinRumors, a site dedicated to Microsoft news, before joining The Verge in 2012. Feb 26, 2024, 3:23 PM UTCShare this story Illustration: The VergeMicrosoft has announced a new multiyear partnership with Mistral, a French AI startup that’s valued at €2 billion (about $2.1 billion).'"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" little helper function to extract only the texts \"\"\"\n",
    "def tools_to_str(tools_output: list) -> str:\n",
    "    return '\\n'.join([tool['chunk'] for tool in tools_output])\n",
    "\n",
    "\n",
    "tools_to_str(mistral_web_search(search_query))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import functools\n",
    "\n",
    "names_to_functions = {\n",
    "    'mistral_web_search': functools.partial(mistral_web_search),\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## chat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [\n",
    "    ChatMessage(role=\"user\", content=\"What happend during apple WWDC 2024?\"),\n",
    "]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatCompletionResponse(id='fb0585bb35c449899283753361aebc7a', object='chat.completion', created=1718068657, model='mistral-large-latest', choices=[ChatCompletionResponseChoice(index=0, message=ChatMessage(role='assistant', content='', name=None, tool_calls=[ToolCall(id='SMqSja1Y4', type=<ToolType.function: 'function'>, function=FunctionCall(name='mistral_web_search', arguments='{\"search_query\": \"apple WWDC 2024\"}'))], tool_call_id=None), finish_reason=<FinishReason.tool_calls: 'tool_calls'>)], usage=UsageInfo(prompt_tokens=121, total_tokens=156, completion_tokens=35))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = \"mistral-large-latest\"\n",
    "\n",
    "client = MistralClient(api_key=MISTRAL_API_KEY)\n",
    "response = client.chat(model=model, messages=messages, tools=tools, tool_choice=\"auto\")\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages.append(response.choices[0].message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "function_name:  mistral_web_search \n",
      "function_params:  {'search_query': 'apple WWDC 2024'}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "tool_call = response.choices[0].message.tool_calls[0]\n",
    "function_name = tool_call.function.name\n",
    "function_params = json.loads(tool_call.function.arguments)\n",
    "\n",
    "\n",
    "print(\"\\nfunction_name: \", function_name, \"\\nfunction_params: \", function_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Apple Intelligence Revealed at WWDC 2024 as Company Jumps Into AI Race - The New York Times\\nSkip to contentSkip to site indexTechnology\\xa0Today’s PaperArtificial IntelligenceApple Enters A.I. FrayMeta’s A.I. ScrapingHumane’s A.I. Device FlopOpenAI’s ‘Reckless’ CultureThe New ChatGPTFaces QuizAdvertisementSKIP ADVERTISEMENTYou have a preview view of this article while we are checking your access. When we have confirmed access, the full article content will load.Artificial IntelligenceApple Enters A.I. FrayMeta’s A.I. ScrapingHumane’s A.I. Device FlopOpenAI’s ‘Reckless’ CultureThe New ChatGPTFaces QuizSupported bySKIP ADVERTISEMENTApple Jumps Into A.I.\\nSigal Samuel, a senior tech reporter for Vox, unpacks what's going on with the company.Apple uses the developer conference at its Cupertino, Calif., headquarters each year to showcase updates to its own apps and operating systems, as well as to show developers new tools they will be able to use in their apps.The company\\xa0has been using AI behind the scenes for years to power features on its devices, such as the ability of its watches to detect crashes and falls.\\nMicrosoft took an early lead in the race to commercialize AI through its bet on OpenAI.The AI features were unveiled at Apple's\\xa0Worldwide Developers Conference, and the tech giant\\xa0also showed its latest operating system for its Vision Pro mixed-reality headset and iPhone.WATCH | Apple launches Apple Intelligence to integrate AI across its apps:Apple announces Apple Intelligence4 hours agoDuration 0:45Partnering with artificial intelligence company OpenAI, Apple announced its iPhones would begin adding AI features.\\n(Associated Press)\\nBy Wendy LeeStaff Writer\\nJune 10, 2024\\nUpdated\\xa02:06 PM PT\\nFacebook\\nTwitter\\nShow more sharing options\\nShare Close extra sharing options\\nFacebook\\nTwitter\\nLinkedIn\\nEmail\\nCopy Link URLCopied!\\nPrint\\nApple is finally taking the plunge on AI. The company on Monday unveiled a suite of new artificial intelligence capabilities that will be available in its newest operating system, including connecting its interactive voice feature Siri with OpenAI’s ChatGPT in a major deal that could supercharge adoption of the fast-developing technology.Siri, for example, will be able to surface answers from ChatGPT for Apple devices and provide relevant contextual information across several apps, the Cupertino, Calif., tech giant said at its highly anticipated developer conference.\\n(Jeff Chiu/AP)Listen6 minShareComment on this storyCommentAdd to your saved storiesSaveSAN FRANCISCO — Apple officially launched itself into the artificial intelligence arms race, announcing a deal with ChatGPT maker OpenAI to use the company’s technology in its products and showing off a slew of its own new AI features.The announcements, made at the tech giant’s annual Worldwide Developers Conference on Monday in Cupertino, Calif., are aimed at helping the tech giant keep up with competitors such as Google and Microsoft, which have boasted in recent months that AI makes their phones, laptops and software better than Apple’s. In addition to Apple’s own homegrown AI tech, the company’s phones, computers and iPads will also have ChatGPT built in “later this year,” a huge validation of the importance of the highflying start-up’s tech.\""
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function_result = tools_to_str(names_to_functions[function_name](**function_params))\n",
    "function_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"At the Apple Worldwide Developers Conference (WWDC) in 2024, Apple made several significant announcements related to artificial intelligence (AI). The tech giant unveiled a suite of new AI capabilities to be integrated into its newest operating system. A notable development was the collaboration with OpenAI's ChatGPT, which aimed to enhance the functionality of Siri, Apple's interactive voice feature. This integration would allow Siri to provide more relevant and contextual information across various apps on Apple devices.\\n\\nThe partnership with OpenAI was seen as a major move to stay competitive with other industry leaders like Google and Microsoft, who had been emphasizing AI integration in their products. Additionally, it was announced that ChatGPT would be built into Apple's phones, computers, and iPads later in the year. This marked a significant step for Apple in the AI race, as they had been utilizing AI behind the scenes for years to power features on their devices.\\n\\nDuring the WWDC 2024, Apple also showcased updates to its own apps and operating systems, as well as new tools for developers to use in their apps. The conference was held at Apple's Cupertino, California headquarters, and demonstrated the company's commitment to advancing AI technology in its products.\""
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messages.append(ChatMessage(role=\"tool\", name=function_name, content=function_result, tool_call_id=tool_call.id))\n",
    "\n",
    "response = client.chat(model=model, messages=messages)\n",
    "response.choices[0].message.content\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chat in a chain (cleaner user experience)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = []\n",
    "\n",
    "while True:\n",
    "    input_ = input(\"Ask: \")\n",
    "    messages.append(ChatMessage(role=\"user\", content=input_))\n",
    "    response = client.chat(model=model, messages=messages, tools=tools, tool_choice=\"auto\")\n",
    "    messages.append(response.choices[0].message)\n",
    "    print(response.choices[0].message.content)\n",
    "    tool_call = response.choices[0].message.tool_calls[0]\n",
    "    function_name = tool_call.function.name\n",
    "    function_params = json.loads(tool_call.function.arguments)\n",
    "\n",
    "    function_result_raw = names_to_functions[function_name](**function_params)\n",
    "    print(\"sources: \", [f\"{source['title']} - {source['url']}\" for source in function_result_raw])\n",
    "    function_result_text = tools_to_str(function_result_raw)\n",
    "    messages.append(ChatMessage(role=\"tool\", name=function_name, content=function_result_text, tool_call_id=tool_call.id))\n",
    "\n",
    "    response = client.chat(model=model, messages=messages)\n",
    "    final_response = response.choices[0].message.content\n",
    "    print(final_response)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mistral-cookbook-contrib",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
