{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mistral AI search engine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![image info](./images/mistral-search-graph.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv()  # load environment variables from .env file\n",
    "MISTRAL_API_KEY = os.getenv(\"MISTRAL_API_KEY\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scraper Definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "MISTRAL_API_KEY = \"WqwvFlb1Amg6yX59txstxCEDwt1jTcln\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching page: 1\n",
      "Fetching page: 2\n"
     ]
    }
   ],
   "source": [
    "import aiohttp\n",
    "import asyncio\n",
    "import nest_asyncio\n",
    "from bs4 import BeautifulSoup\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "import requests\n",
    "import re\n",
    "import pandas as pd\n",
    "import faiss\n",
    "import numpy as np\n",
    "from mistralai.client import MistralClient\n",
    "from mistralai.models.chat_completion import ChatMessage\n",
    "\n",
    "# Apply the nest_asyncio patch\n",
    "nest_asyncio.apply()\n",
    "\n",
    "headers = {\n",
    "    \"User-Agent\": \"Mozilla/5.0 (Windows NT 6.1; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/108.0.0.0 Safari/537.36\"\n",
    "}\n",
    "\n",
    "total_results_to_fetch = 10  # total number of results to fetch\n",
    "chunk_size = 1000  # size of each text chunk\n",
    "\n",
    "dataframe_out_path = 'temp.csv'\n",
    "faiss_index_path = 'faiss_index.index'\n",
    "\n",
    "mistral_api_key = MISTRAL_API_KEY  # replace with your actual API key\n",
    "\n",
    "async def fetch(session, url, params=None):\n",
    "    async with session.get(url, params=params, headers=headers, timeout=30) as response:\n",
    "        return await response.text()\n",
    "\n",
    "async def fetch_page(session, params, page_num, results):\n",
    "    print(f\"Fetching page: {page_num}\")\n",
    "    params[\"start\"] = (page_num - 1) * params[\"num\"]\n",
    "    html = await fetch(session, \"https://www.google.com/search\", params)\n",
    "    soup = BeautifulSoup(html, 'html.parser')\n",
    "\n",
    "    for result in soup.select(\".tF2Cxc\"):\n",
    "        if len(results) >= total_results_to_fetch:\n",
    "            break\n",
    "        title = result.select_one(\".DKV0Md\").text\n",
    "        links = result.select_one(\".yuRUbf a\")[\"href\"]\n",
    "\n",
    "        results.append({\n",
    "            \"title\": title,\n",
    "            \"links\": links\n",
    "        })\n",
    "\n",
    "async def fetch_content(session, url):\n",
    "    async with session.get(url, headers=headers, timeout=30) as response:\n",
    "        return await response.text()\n",
    "\n",
    "async def fetch_all_content(urls):\n",
    "    async with aiohttp.ClientSession() as session:\n",
    "        tasks = [fetch_content(session, url) for url in urls]\n",
    "        return await asyncio.gather(*tasks)\n",
    "\n",
    "def get_all_text_from_url(url):\n",
    "    response = requests.get(url, headers=headers, timeout=30)\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "    for script in soup([\"script\", \"style\"]):\n",
    "        script.extract()\n",
    "    text = soup.get_text()\n",
    "    lines = (line.strip() for line in text.splitlines())\n",
    "    chunks = (phrase.strip() for line in lines for phrase in line.split(\"  \"))\n",
    "    text = '\\n'.join(chunk for chunk in chunks if chunk)\n",
    "    return text\n",
    "\n",
    "def split_text_into_chunks(text, chunk_size):\n",
    "    sentences = re.split(r'(?<=[.!?]) +', text)\n",
    "    chunks = []\n",
    "    current_chunk = []\n",
    "\n",
    "    for sentence in sentences:\n",
    "        if sum(len(s) for s in current_chunk) + len(sentence) + 1 > chunk_size:\n",
    "            chunks.append(' '.join(current_chunk))\n",
    "            current_chunk = [sentence]\n",
    "        else:\n",
    "            current_chunk.append(sentence)\n",
    "\n",
    "    if current_chunk:\n",
    "        chunks.append(' '.join(current_chunk))\n",
    "\n",
    "    return chunks\n",
    "\n",
    "async def process_text_content(texts, chunk_size):\n",
    "    loop = asyncio.get_event_loop()\n",
    "    tasks = [loop.run_in_executor(None, split_text_into_chunks, text, chunk_size) for text in texts]\n",
    "    return await asyncio.gather(*tasks)\n",
    "\n",
    "async def get_embeddings_from_mistral(client, text_chunks):\n",
    "    response = client.embeddings(model=\"mistral-embed\", input=text_chunks)\n",
    "    return [embedding.embedding for embedding in response.data]\n",
    "\n",
    "async def fetch_and_process_data(search_query):\n",
    "    client = MistralClient(api_key=mistral_api_key)\n",
    "\n",
    "    params = {\n",
    "        \"q\": search_query,  # query example\n",
    "        \"hl\": \"en\",         # language\n",
    "        \"gl\": \"uk\",         # country of the search, UK -> United Kingdom\n",
    "        \"start\": 0,         # number page by default up to 0\n",
    "        \"num\": 10           # parameter defines the maximum number of results to return per page.\n",
    "    }\n",
    "    \n",
    "    async with aiohttp.ClientSession() as session:\n",
    "        page_num = 0\n",
    "        results = []\n",
    "        while len(results) < total_results_to_fetch:\n",
    "            page_num += 1\n",
    "            await fetch_page(session, params, page_num, results)\n",
    "\n",
    "        urls = [result['links'] for result in results]\n",
    "\n",
    "        with ThreadPoolExecutor(max_workers=10) as executor:\n",
    "            loop = asyncio.get_event_loop()\n",
    "            texts = await asyncio.gather(\n",
    "                *[loop.run_in_executor(executor, get_all_text_from_url, url) for url in urls]\n",
    "            )\n",
    "\n",
    "        chunks_list = await process_text_content(texts, chunk_size)\n",
    "\n",
    "        embeddings_list = []\n",
    "        for chunks in chunks_list:\n",
    "            embeddings = await get_embeddings_from_mistral(client, chunks)\n",
    "            embeddings_list.append(embeddings)\n",
    "\n",
    "        data = []\n",
    "        for i, result in enumerate(results):\n",
    "            if i >= len(embeddings_list):\n",
    "                print(f\"Error: No embeddings returned for result {i}\")\n",
    "                continue\n",
    "            for j, chunk in enumerate(chunks_list[i]):\n",
    "                if j >= len(embeddings_list[i]):\n",
    "                    print(f\"Error: No embedding returned for chunk {j} of result {i}\")\n",
    "                    continue\n",
    "                data.append({\n",
    "                    'title': result['title'],\n",
    "                    'url': result['links'],\n",
    "                    'chunk': chunk,\n",
    "                    'embedding': embeddings_list[i][j]\n",
    "                })\n",
    "\n",
    "        df = pd.DataFrame(data)\n",
    "        df.to_csv(dataframe_out_path, index=False)\n",
    "\n",
    "        # FAISS indexing\n",
    "        dimension = len(embeddings_list[0][0])  # assuming all embeddings have the same dimension\n",
    "        index = faiss.IndexFlatL2(dimension)\n",
    "\n",
    "        embeddings = np.array([entry['embedding'] for entry in data], dtype=np.float32)\n",
    "        index.add(embeddings)\n",
    "\n",
    "        faiss.write_index(index, faiss_index_path)\n",
    "\n",
    "await fetch_and_process_data(\"What is the latest news about apple and openai?\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## little embeddings and vector store creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'title': 'Apple announces deal with OpenAI. Will it be a game- ...',\n",
       "  'url': 'https://www.latimes.com/entertainment-arts/business/story/2024-06-10/apple-announces-leap-into-ai-will-it-be-a-game-changer',\n",
       "  'chunk': '“This is a method to allow Apple to make up for the fact that they haven’t been focused on AI like they should have done over the last decade or so.” Apple Intelligence was one of many announcements and updates from Apple\\non Monday, including a feature that lets AirPods Pro users nod yes or shake their heads no to Siri’s questions when they are in crowded spaces. Additionally, the company announced that the\\nVision Pro headset will also be available in additional countries starting later this month, including mainland China, Hong Kong, Japan and Singapore.The company also unveiled a new feature called InSight for its tvOS18 that is similar to Amazon’s X-Ray and shows the names of actors or a song playing on an Apple TV+ program.\\nCompany Town\\nScarlett Johansson also thinks OpenAI’s new voice sounds like her. She’s not happy about it\\nJohansson, who portrayed the voice of a computer program in ‘Her,’ was not behind OpenAI’s ‘Sky’ voice assistant.'},\n",
       " {'title': 'Apple doubles down on artificial intelligence, announcing ...',\n",
       "  'url': 'https://www.npr.org/2024/06/10/nx-s1-4999051/apple-artificial-intelligence-partnership-openai-chatgpt-siri-iphone',\n",
       "  'chunk': \"OpenAI itself has been embroiled in allegations of copying actor Scartlett Johansson’s voice without her permission. Apple is also at the center of an antitrust lawsuit filed by the Justice Department and 15 states. The government accuses Apple of abusing its power as a monopoly to push out rivals and keep customers using its products. It’s unclear how Apple’s new partnership with OpenAI could play into this case. Shortly after Apple’s announcement, OpenAI CEO Sam Altman posted on X, formerly known as Twitter, “very happy to be partnering with apple to integrate chatgpt into their devices later this year! think you will really like it.”\\nApple is also rolling out what it calls Apple Intelligence, its term for Apple's own new generative AI software. Apple Intelligence will enable transcription for phone calls, AI photo retouching and improvements in the natural conversation flow with Siri, the company said.\"},\n",
       " {'title': 'Apple announces deal with OpenAI. Will it be a game- ...',\n",
       "  'url': 'https://www.latimes.com/entertainment-arts/business/story/2024-06-10/apple-announces-leap-into-ai-will-it-be-a-game-changer',\n",
       "  'chunk': 'Tools made by San Francisco-based OpenAI have been used to create\\nmusic videos, read bedtime stories to children and help brainstorm ideas for writers. Companies including Microsoft and Google have aggressively incorporated AI into their products and services. Apple has often not been the first to market with new technological advances, choosing instead to enter new product categories — including smartphones and tablets — once they’ve been established, leading to broader consumer adoption. For example, Apple only began selling its own virtual and augmented reality headset (known as Vision Pro) early this year.\\nApple said its AI capabilities were created with privacy protections in mind.'},\n",
       " {'title': 'Apple announces deal with OpenAI. Will it be a game- ...',\n",
       "  'url': 'https://www.latimes.com/entertainment-arts/business/story/2024-06-10/apple-announces-leap-into-ai-will-it-be-a-game-changer',\n",
       "  'chunk': 'Apple announces deal with OpenAI. Will it be a game-changer? - Los Angeles Times\\nNews\\nHome Page\\nCalifornia\\nElection 2024\\nHousing & Homelessness\\nPolitics\\nScience & Medicine\\nWorld & Nation\\nBusiness\\nArtificial Intelligence\\nAutos\\nJobs, Labor & Workplace\\nReal Estate\\nTechnology and the Internet\\nCalifornia\\nCalifornia Politics\\nEarthquakes\\nEducation\\nHousing & Homelessness\\nL.A. Influential\\nL.A. Politics\\nMental Health\\nClimate & Environment\\nGlobal Warming\\nWater & Drought\\nEntertainment & Arts\\nArts\\nBooks\\nStand-Up Comedy\\nCompany Town\\nThe Envelope (Awards)\\nMovies\\nMusic\\nTelevision\\nThings to Do\\nDe Los\\nEn Español\\nFood\\n101 best restaurants in L.A.\\nRecipes\\nImage\\nLifestyle\\nHealth & Wellness\\nHome Design\\nL.A.'},\n",
       " {'title': 'OpenAI and Apple announce partnership',\n",
       "  'url': 'https://openai.com/index/openai-and-apple-announce-partnership/',\n",
       "  'chunk': \"Together with Apple, we're making it easier for people to benefit from what AI can offer.Sam Altman, CEO of OpenAIAnnouncementsCompanyAuthorOpenAI Our researchOverviewIndexLatest advancementsGPT-4DALL·E 3SoraChatGPTFor EveryoneFor TeamsFor EnterprisesChatGPT login(opens in a new window)APIPlatform overviewPricingDocumentation(opens in a new window)API login(opens in a new window)Explore moreOpenAI for businessStoriesSafety overviewSafety overviewSafety standardsTeamsSafety SystemsPreparednessSuperalignmentCompanyAbout usNewsOur CharterSecurityResidencyCareersTerms & policiesTerms of usePrivacy policyBrand guidelinesOther policies OpenAI © 2015–2024(opens in a new window)(opens in a new window)(opens in a new window)(opens in a new window)(opens in a new window)(opens in a new window)(opens in a new window)\"}]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def query_vector_store(query_embedding, k=5):\n",
    "    \"\"\"\n",
    "    Query the FAISS vector store and return the text results along with metadata.\n",
    "\n",
    "    :param query_embedding: The embedding to query with.\n",
    "    :param k: Number of nearest neighbors to retrieve.\n",
    "    :return: List of dictionaries containing text results and metadata of the k nearest neighbors.\n",
    "    \"\"\"\n",
    "    # Load the index\n",
    "\n",
    "    index = faiss.read_index(faiss_index_path)\n",
    "\n",
    "    # Ensure the query embedding is a numpy array with the correct shape\n",
    "    if not isinstance(query_embedding, np.ndarray):\n",
    "        query_embedding = np.array(query_embedding, dtype=np.float32)\n",
    "    if query_embedding.ndim == 1:\n",
    "        query_embedding = np.expand_dims(query_embedding, axis=0)\n",
    "\n",
    "    # Query the index\n",
    "    distances, indices = index.search(query_embedding, k)\n",
    "    \n",
    "    # Load the dataframe\n",
    "    df = pd.read_csv(dataframe_out_path)\n",
    "    \n",
    "    # Retrieve the text results and metadata\n",
    "    results = []\n",
    "    for idx in indices[0]:\n",
    "        result = {\n",
    "            'title': df.iloc[idx]['title'],\n",
    "            'url': df.iloc[idx]['url'],\n",
    "            'chunk': df.iloc[idx]['chunk']\n",
    "        }\n",
    "        results.append(result)\n",
    "    \n",
    "    return results\n",
    "\n",
    "def query_embeddings(texts):\n",
    "    \"\"\"\n",
    "    Convert text to embeddings using Mistral AI API.\n",
    "\n",
    "    :param api_key: Your Mistral API key.\n",
    "    :param texts: List of texts to convert to embeddings.\n",
    "    :return: List of embeddings.\n",
    "    \"\"\"\n",
    "    client = MistralClient(api_key=MISTRAL_API_KEY)\n",
    "    response = client.embeddings(model=\"mistral-embed\", input=[texts])\n",
    "    return [embedding.embedding for embedding in response.data]\n",
    "\n",
    "\n",
    "embeddings = query_embeddings(\"AGI\")\n",
    "results = query_vector_store(embeddings[0], k=5)\n",
    "results\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## tools definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching page: 1\n",
      "Fetching page: 2\n",
      "[{'title': 'How Mistral AI, an OpenAI competitor, rocketed to $2Bn in ...', 'url': 'https://www.bensbites.com/case-study/how-mistral-ai-an-openai-competitor-rocketed-to-2bn-in-12-months', 'chunk': 'Something went wrong while submitting the form.PricingLog inSign upCase studies\\nHow Mistral AI, an OpenAI competitor, rocketed to $2Bn in <12 monthsHow Mistral AI, an OpenAI competitor, rocketed to $2Bn in <12 monthsSaveSavedToday Iâ\\x80\\x99m diving deep into Mistral AI, who are making headlines after recently closing their (huge) Series A round. Launched just 7 months ago, theyâ\\x80\\x99re disrupting the LLM market. I want to look at how theyâ\\x80\\x99re doing it - and how you can take advantage.This post covers:What is Mistral?Whoâ\\x80\\x99s behind it?The timeline: Whatâ\\x80\\x99s happened to dateFundraisingProduct OverviewA peek inside their seed deck ð\\x9f\\x91\\x80 Roadmap analysis. Are they achieving what they set out to do?5 big reasons Mistralâ\\x80\\x99s making waves ð\\x9f\\x8c\\x8aHow people actually use MistralOpportunities and how you can take advantageWhat developers think of MistralWhat is Mistral?A French startup that develops fast, open-source and secure language models.'}, {'title': 'How Mistral AI, an OpenAI competitor, rocketed to $2Bn in ...', 'url': 'https://www.bensbites.com/case-study/how-mistral-ai-an-openai-competitor-rocketed-to-2bn-in-12-months', 'chunk': 'As Mistral has been true to the promise of releasing open models, the community (and other companies) have taken Mistralâ\\x80\\x99s models and created better models on top of them. For example, OpenHermes 2.5 by Teknium and Neural Chat 7B by Intel.With AI models, open source takes many forms: from available to use locally but no details about the model (weights, architecture etc.) to models that are fully open source and allow users to train on the outputs.While Mistralâ\\x80\\x99s models were open-weights from the start, Mistralâ\\x80\\x99s latest announcement had a line in their Terms of Service Terms of Service which was spotted by Far El on Twitter, said:Basically, you canâ\\x80\\x99t use it to train or improve other models or compete against themâ\\x80¦It wasnâ\\x80\\x99t clear whether this was just for the API platform or the model itself. And unfortunately, open-source means you should be able to use this tech how you like, thatâ\\x80\\x99s kind of the point.'}, {'title': \"All you need to know about OpenAI's rival Mistral AI ...\", 'url': 'https://m.economictimes.com/tech/technology/ettech-explainer-all-you-need-to-know-about-openais-rival-mistral-ai/articleshow/108032666.cms', 'chunk': 'Mistral 8x7B model surpasses GPT 3.5 and Llama 2 on performance benchmarks, reducing deployment costs. Mistral raised $415 million in funding.Getty ImagesArthur Mensch, cofounder and CEO, Mistral AITech giant Microsoft has partnered with Paris-based generative artificial intelligence (AI) startup Mistral AI which would allow the latter’s AI models to run on Microsoft’s Azure cloud computing platform. Modi 3.0 LiveModi 3.0 is here!'}, {'title': 'How Mistral AI, an OpenAI competitor, rocketed to $2Bn in ...', 'url': 'https://www.bensbites.com/case-study/how-mistral-ai-an-openai-competitor-rocketed-to-2bn-in-12-months', 'chunk': 'Founded in 2023 by Arthur Mensch, Guillaume Lample, and TimothÃ©e Lacroix.Theyâ\\x80\\x99ve raised over $650M in funding, are valued at $2Bn, are less than a year old and have 22 employees.monthly search volume for â\\x80\\x98mistral aiâ\\x80\\x99The company is important for a few reasons;Itâ\\x80\\x99s actually open-source, you know like OpenAI was supposed to be? Or how LlaMA by Meta kinda is but isnâ\\x80\\x99t?Itâ\\x80\\x99s developed 2 AI models in less than a year.Itâ\\x80\\x99s French.The founders are 3 researchers from DeepMind and Meta who aimed to beat GPT 3.5 by year-end.'}, {'title': 'How Mistral AI, an OpenAI competitor, rocketed to $2Bn in ...', 'url': 'https://www.bensbites.com/case-study/how-mistral-ai-an-openai-competitor-rocketed-to-2bn-in-12-months', 'chunk': 'The big debate.Mistral believes (as do many others, myself included) that there are several concerns with closed AI approaches; businesses have to send sensitive data to it, only exposing the outputs doesnâ\\x80\\x99t help connect with other components (retrieval, structure inputs etc) and the data used to train the models are secret (so we assume it can do some things it perhaps hasnâ\\x80\\x99t been trained on).Now the bold stuff.â\\x80\\x9cMistral will offer the best technology in 4 yearsâ\\x80\\x9d.How?Theyâ\\x80\\x99ll take a more open approach to model development.Tighter integration with customersâ\\x80\\x99 workflows.Increase focus on data sources and control.Propose unmatched guarantees on security and privacy.Thereâ\\x80\\x99s a lot more detail in their deck on the above 4 points.As far as business focus goesâ\\x80¦â\\x80\\x9cOn the business side, we will provide the most valuable technology brick to the emerging AI-as-a-service industry that will revolutionise business workflows with generative AI.'}]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "nest_asyncio.apply()\n",
    "\n",
    "tools = [\n",
    "    {\n",
    "        \"type\": \"function\",\n",
    "        \"function\": {\n",
    "            \"name\": \"mistral_web_search\",\n",
    "            \"description\": \"Fetch and process data from Google search based on a query, store results in FAISS vector store, and retrieve results.\",\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"search_query\": {\n",
    "                        \"type\": \"string\",\n",
    "                        \"description\": \"The search query to use for fetching data from Google search.\"\n",
    "                    }\n",
    "                },\n",
    "                \"required\": [\"search_query\"]\n",
    "            },\n",
    "        },\n",
    "    },\n",
    "]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def mistral_web_search(search_query: str):\n",
    "    async def run_search():\n",
    "        await fetch_and_process_data(search_query)\n",
    "        embeddings = query_embeddings(search_query)\n",
    "        results_ = query_vector_store(embeddings[0], k=5)\n",
    "        return results_\n",
    "\n",
    "    return asyncio.run(run_search())\n",
    "\n",
    "search_query = \"mistral and openai\"\n",
    "results = mistral_web_search(search_query)\n",
    "print(results)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching page: 1\n",
      "Fetching page: 2\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Mistral has also previously said it is teaming up with other big cloud providers including Amazon and Google.\\nRELATED COVERAGE\\nUS antitrust enforcers will investigate leading AI companies Microsoft, Nvidia and OpenAI\\nAI ‘gold rush’ for chatbot training data could run out of human-written text\\nFormer OpenAI employees lead push to protect whistleblowers flagging artificial intelligence risks\\nMistral made a big splash by attracting big amounts of investor funding to give it a multibillion-dollar valuation just months after it was founded last spring. It was started by three French former researchers from Google and Meta: CEO Arthur Mensch, Chief Scientist Guillaume Lample and Chief Technology Officer Timothee Lacroix.\\nIt has advertised an “open-source” approach to developing AI that involves publicly releasing key components of some AI systems, in contrast to companies such as OpenAI that closely guard them.\\nSomething went wrong while submitting the form.PricingLog inSign upCase studies\\nHow Mistral AI, an OpenAI competitor, rocketed to $2Bn in <12 monthsHow Mistral AI, an OpenAI competitor, rocketed to $2Bn in <12 monthsSaveSavedToday Iâ\\x80\\x99m diving deep into Mistral AI, who are making headlines after recently closing their (huge) Series A round. Launched just 7 months ago, theyâ\\x80\\x99re disrupting the LLM market. I want to look at how theyâ\\x80\\x99re doing it - and how you can take advantage.This post covers:What is Mistral?Whoâ\\x80\\x99s behind it?The timeline: Whatâ\\x80\\x99s happened to dateFundraisingProduct OverviewA peek inside their seed deck ð\\x9f\\x91\\x80 Roadmap analysis. Are they achieving what they set out to do?5 big reasons Mistralâ\\x80\\x99s making waves ð\\x9f\\x8c\\x8aHow people actually use MistralOpportunities and how you can take advantageWhat developers think of MistralWhat is Mistral?A French startup that develops fast, open-source and secure language models.\\nAs Mistral has been true to the promise of releasing open models, the community (and other companies) have taken Mistralâ\\x80\\x99s models and created better models on top of them. For example, OpenHermes 2.5 by Teknium and Neural Chat 7B by Intel.With AI models, open source takes many forms: from available to use locally but no details about the model (weights, architecture etc.) to models that are fully open source and allow users to train on the outputs.While Mistralâ\\x80\\x99s models were open-weights from the start, Mistralâ\\x80\\x99s latest announcement had a line in their Terms of Service Terms of Service which was spotted by Far El on Twitter, said:Basically, you canâ\\x80\\x99t use it to train or improve other models or compete against themâ\\x80¦It wasnâ\\x80\\x99t clear whether this was just for the API platform or the model itself. And unfortunately, open-source means you should be able to use this tech how you like, thatâ\\x80\\x99s kind of the point.\\nFounded in 2023 by Arthur Mensch, Guillaume Lample, and TimothÃ©e Lacroix.Theyâ\\x80\\x99ve raised over $650M in funding, are valued at $2Bn, are less than a year old and have 22 employees.monthly search volume for â\\x80\\x98mistral aiâ\\x80\\x99The company is important for a few reasons;Itâ\\x80\\x99s actually open-source, you know like OpenAI was supposed to be? Or how LlaMA by Meta kinda is but isnâ\\x80\\x99t?Itâ\\x80\\x99s developed 2 AI models in less than a year.Itâ\\x80\\x99s French.The founders are 3 researchers from DeepMind and Meta who aimed to beat GPT 3.5 by year-end.\\nThe big debate.Mistral believes (as do many others, myself included) that there are several concerns with closed AI approaches; businesses have to send sensitive data to it, only exposing the outputs doesnâ\\x80\\x99t help connect with other components (retrieval, structure inputs etc) and the data used to train the models are secret (so we assume it can do some things it perhaps hasnâ\\x80\\x99t been trained on).Now the bold stuff.â\\x80\\x9cMistral will offer the best technology in 4 yearsâ\\x80\\x9d.How?Theyâ\\x80\\x99ll take a more open approach to model development.Tighter integration with customersâ\\x80\\x99 workflows.Increase focus on data sources and control.Propose unmatched guarantees on security and privacy.Thereâ\\x80\\x99s a lot more detail in their deck on the above 4 points.As far as business focus goesâ\\x80¦â\\x80\\x9cOn the business side, we will provide the most valuable technology brick to the emerging AI-as-a-service industry that will revolutionise business workflows with generative AI.'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" little helper function to extract only the texts \"\"\"\n",
    "def tools_to_str(tools_output: list) -> str:\n",
    "    return '\\n'.join([tool['chunk'] for tool in tools_output])\n",
    "\n",
    "\n",
    "tools_to_str(mistral_web_search(search_query))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import functools\n",
    "\n",
    "names_to_functions = {\n",
    "    'mistral_web_search': functools.partial(mistral_web_search),\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## chat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [\n",
    "    ChatMessage(role=\"user\", content=\"What happend during apple WWDC 2024?\"),\n",
    "]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatCompletionResponse(id='ef8acfcbd94342a7ba0878d2aee7a26f', object='chat.completion', created=1718094423, model='mistral-large-latest', choices=[ChatCompletionResponseChoice(index=0, message=ChatMessage(role='assistant', content='', name=None, tool_calls=[ToolCall(id='X25J2hDYB', type=<ToolType.function: 'function'>, function=FunctionCall(name='mistral_web_search', arguments='{\"search_query\": \"apple WWDC 2024\"}'))], tool_call_id=None), finish_reason=<FinishReason.tool_calls: 'tool_calls'>)], usage=UsageInfo(prompt_tokens=121, total_tokens=156, completion_tokens=35))"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = \"mistral-large-latest\"\n",
    "\n",
    "client = MistralClient(api_key=MISTRAL_API_KEY)\n",
    "response = client.chat(model=model, messages=messages, tools=tools, tool_choice=\"any\")\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages.append(response.choices[0].message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "function_name:  mistral_web_search \n",
      "function_params:  {'search_query': 'apple WWDC 2024'}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "tool_call = response.choices[0].message.tool_calls[0]\n",
    "function_name = tool_call.function.name\n",
    "function_params = json.loads(tool_call.function.arguments)\n",
    "\n",
    "\n",
    "print(\"\\nfunction_name: \", function_name, \"\\nfunction_params: \", function_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching page: 1\n",
      "Fetching page: 2\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"Apple WWDC 2024: the 13 biggest announcements - The VergeSkip to main contentThe VergeThe Verge logo.The Verge homepageThe Verge homepageThe VergeThe Verge logo./Tech/Reviews/Science/Entertainment/AI/MoreMenuExpandThe VergeThe Verge logo.MenuExpandWWDC 2024/Apple/TechApple WWDC 2024: the 13 biggest announcementsApple WWDC 2024: the 13 biggest announcements / Apple’s WWDC keynote had a lot to do with AI.By\\nEmma Roth, a news writer who covers the streaming wars, consumer tech, crypto, social media, and much more. Previously, she was a writer and editor at MUO.\\nJun 10, 2024, 6:57 PM UTCShare this storyApple’s Worldwide Developers Conference keynote has come to a close — and the company had a whole lot to share.\\nFifty Distinguished Winners, who are recognised for outstanding submissions, will be invited to Cupertino for a three-day experience.\\nApple will share additional conference information in advance of WWDC24 through the Apple Developer app and website.\\nShare article\\nMedia\\nText of this article\\n26 March 2024\\nPRESS RELEASE\\nApple’s Worldwide Developers Conference returns June 10, 2024\\nEntire conference available online for all developers, with a special event at Apple Park on June 10\\nCUPERTINO, CALIFORNIA Apple today announced it will host its annual Worldwide Developers Conference (WWDC) online from June 10 through 14, 2024. Developers and students will have the opportunity to celebrate in person at a special event at Apple Park on opening day.\\nFree for all developers, WWDC24 will spotlight the latest iOS, iPadOS, macOS, watchOS, tvOS, and visionOS advancements.\\niPadOS could finally get new apps like a native calculator, and some rumored new Apple Pencil 3 features.\\xa0We expect macOS to offer AI features, with native apps that lean on smart tools and generative AI: assisted writing in Pages, a slide deck maker in Keynote, coding in Xcode, all powered by AI.\\xa0When it comes to the Vision Pro and visionOS, we haven't heard much, so we're expecting a nod to spatial computing, but nothing huge coming yet. For wearables, we're not expecting big watchOS changes with watchOS 11, either.Watch WWDC 2024 live with usWWDC 2024 as it happens\\nRefresh\\n2024-06-10T16:26:28.008Z\\nGood morning, good afternoon and good evening, wherever you are in the world – and welcome to TechRadar's live coverage of WWDC 2024.\\n2024-06-10T16:45:58.710Z\\n(Image credit: Jacob Krol / Future)Apple's WWDC 2024 keynote is minutes away, with rumors swirling about \\xa0announcements focusing on artificial intelligence and Siri, Apple's languishing voice assistant.\\nThis year’s conference will include video sessions and opportunities to engage with Apple designers and engineers and connect with the worldwide developer community.\\nWWDC24 will include an in-person experience on June 10 that will provide developers the opportunity to watch the keynote at Apple Park, meet with Apple team members, and take part in special activities. Space will be limited, and details on how to apply to attend can be found on the Apple Developer site and app.\\nApple is proud to support the next generation of developers through the Swift Student Challenge, one of many Apple programs that seek to uplift the next generation of developers, creators, and entrepreneurs. On March 28, this year’s applicants will be notified of their status, and winners will be eligible to apply for the in-person experience at Apple Park. Fifty Distinguished Winners, who are recognised for outstanding submissions, will be invited to Cupertino for a three-day experience.\\nThis year’s conference will include video sessions and opportunities to engage with Apple designers and engineers and connect with the worldwide developer community.\\nWWDC24 will include an in-person experience on June 10 that will provide developers the opportunity to watch the keynote at Apple Park, meet with Apple team members, and take part in special activities. Space will be limited, and details on how to apply to attend can be found on the Apple Developer site and app.\\nApple is proud to support the next generation of developers through the Swift Student Challenge, one of many Apple programs that seek to uplift the next generation of developers, creators, and entrepreneurs. On March 28, this year’s applicants will be notified of their status, and winners will be eligible to apply for the in-person experience at Apple Park.\""
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function_result = tools_to_str(names_to_functions[function_name](**function_params))\n",
    "function_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"I found some information about Apple's WWDC 2024. Here are the key points:\\n\\n* The conference took place from June 10 through 14, 2024.\\n* It was an online event, but there was a special in-person experience at Apple Park on opening day for developers and students.\\n* The conference focused on the latest advancements in iOS, iPadOS, macOS, watchOS, tvOS, and visionOS.\\n* iPadOS received new apps like a native calculator, and there were rumors of new Apple Pencil 3 features.\\n* macOS offered AI features, with native apps that leaned on smart tools and generative AI: assisted writing in Pages, a slide deck maker in Keynote, coding in Xcode, all powered by AI.\\n* The event also included video sessions and opportunities to engage with Apple designers and engineers and connect with the worldwide developer community.\\n* Apple supported the next generation of developers through the Swift Student Challenge, with 50 Distinguished Winners being invited to Cupertino for a three-day experience.\\n\\nUnfortunately, I could not find specific details about the 13 biggest announcements. However, based on the information available, it seems that AI and machine learning played a significant role in the conference.\""
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messages.append(ChatMessage(role=\"tool\", name=function_name, content=function_result, tool_call_id=tool_call.id))\n",
    "\n",
    "response = client.chat(model=model, messages=messages)\n",
    "response.choices[0].message.content\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chat in a chain (cleaner user experience)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = []\n",
    "\n",
    "while True:\n",
    "    input_ = input(\"Ask: \")\n",
    "    messages.append(ChatMessage(role=\"user\", content=input_))\n",
    "    response = client.chat(model=model, messages=messages, tools=tools, tool_choice=\"auto\")\n",
    "    messages.append(response.choices[0].message)\n",
    "    print(response.choices[0].message.content)\n",
    "    tool_call = response.choices[0].message.tool_calls[0]\n",
    "    function_name = tool_call.function.name\n",
    "    function_params = json.loads(tool_call.function.arguments)\n",
    "\n",
    "    function_result_raw = names_to_functions[function_name](**function_params)\n",
    "    print(\"sources: \", [f\"{source['title']} - {source['url']}\" for source in function_result_raw])\n",
    "    function_result_text = tools_to_str(function_result_raw)\n",
    "    messages.append(ChatMessage(role=\"tool\", name=function_name, content=function_result_text, tool_call_id=tool_call.id))\n",
    "\n",
    "    response = client.chat(model=model, messages=messages)\n",
    "    final_response = response.choices[0].message.content\n",
    "    print(final_response)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mistral-cookbook-contrib",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
